# üéØ –ü–æ–∫—Ä–∞—â–µ–Ω—ñ SVD —Ç–∞ KNN –ê–ª–≥–æ—Ä–∏—Ç–º–∏ - –¢–µ—Ö–Ω—ñ—á–Ω–∏–π –û–≥–ª—è–¥

## üìã –ó–º—ñ—Å—Ç

1. [–ó–∞–≥–∞–ª—å–Ω–∏–π –æ–≥–ª—è–¥ –ø–æ–∫—Ä–∞—â–µ–Ω—å](#–∑–∞–≥–∞–ª—å–Ω–∏–π-–æ–≥–ª—è–¥-–ø–æ–∫—Ä–∞—â–µ–Ω—å)
2. [SVD (Matrix Factorization) –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è](#svd-matrix-factorization-–ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è)
3. [KNN (Collaborative Filtering) –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è](#knn-collaborative-filtering-–ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è)
4. [–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–µ –û–±“ë—Ä—É–Ω—Ç—É–≤–∞–Ω–Ω—è](#–º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–µ-–æ–±“ë—Ä—É–Ω—Ç—É–≤–∞–Ω–Ω—è)
5. [–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ç–∞ –í–∞–ª—ñ–¥–∞—Ü—ñ—è](#—Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è-—Ç–∞-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è)

## üöÄ –ó–∞–≥–∞–ª—å–Ω–∏–π –æ–≥–ª—è–¥ –ø–æ–∫—Ä–∞—â–µ–Ω—å

### –û—Å–Ω–æ–≤–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—ó:
- ‚ùå **SVD**: –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–∞—Ç—Ä–∏—Ü—ñ, –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å bias correction
- ‚ùå **KNN**: –ø—Ä–æ–±–ª–µ–º–∏ –∑ —Ä–æ–∑—Ä—ñ–¥–∂–µ–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏, –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ —Å—Ö–æ–∂–æ—Å—Ç—ñ
- ‚ùå **–ó–∞–≥–∞–ª—å–Ω—ñ**: –ø–æ–≥–∞–Ω–∞ –æ–±—Ä–æ–±–∫–∞ cold start, –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å fallback –º–µ—Ö–∞–Ω—ñ–∑–º—ñ–≤

### –ö–ª—é—á–æ–≤—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è:
- ‚úÖ **–ü—Ä–∞–≤–∏–ª—å–Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è** –∑–≥—ñ–¥–Ω–æ –∑ –Ω–∞—É–∫–æ–≤–∏–º–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏
- ‚úÖ **Bias correction** –¥–ª—è –ø—ñ–¥–≤–∏—â–µ–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å
- ‚úÖ **Robust fallback –º–µ—Ö–∞–Ω—ñ–∑–º–∏** –¥–ª—è –Ω–æ–≤–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
- ‚úÖ **–ï—Ñ–µ–∫—Ç–∏–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Ä–æ–∑—Ä—ñ–¥–∂–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö**
- ‚úÖ **–ü–æ–∫—Ä–∞—â–µ–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ**

---

## üîÑ SVD (Matrix Factorization) –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è

### 1. –ü—Ä–∞–≤–∏–ª—å–Ω–∞ –ú–∞—Ç—Ä–∏—á–Ω–∞ –§–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è

**–ü–æ–ø–µ—Ä–µ–¥–Ω—è —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ: SVD –Ω–∞ transpose –º–∞—Ç—Ä–∏—Ü—ñ
items_matrix = user_item_matrix.T.values
self.svd_model.fit(items_matrix)
```

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: SVD –Ω–∞ user-item –º–∞—Ç—Ä–∏—Ü—ñ –∑ bias correction
bias_corrected_matrix = self._apply_bias_correction(user_item_matrix)
U_reduced = self.svd_model.fit_transform(bias_corrected_matrix)
Vt_reduced = self.svd_model.components_
```

### 2. Bias Correction Formula

–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∞ —Ñ–æ—Ä–º—É–ª–∞ –¥–ª—è bias correction:

```
rÃÇ·µ§·µ¢ = Œº + b·µ§ + b·µ¢ + q·µ¢·µÄp·µ§
```

–î–µ:
- `Œº` = –≥–ª–æ–±–∞–ª—å–Ω–∏–π —Å–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–π—Ç–∏–Ω–≥
- `b·µ§` = bias –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ u (r·µ§ - Œº)
- `b·µ¢` = bias –µ–ª–µ–º–µ–Ω—Ç–∞ i (r·µ¢ - Œº)
- `q·µ¢·µÄp·µ§` = –ª–∞—Ç–µ–Ω—Ç–Ω–∏–π —Ñ–∞–∫—Ç–æ—Ä–Ω–∏–π —Å–∫–æ—Ä

**–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
def _train_improved_svd_model(self, data):
    # –û–±—á–∏—Å–ª—é—î–º–æ bias terms
    self.global_mean = np.mean(ratings)
    self.user_means = np.array([user_mean for each user])
    self.item_means = np.array([item_mean for each item])
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ bias-corrected –º–∞—Ç—Ä–∏—Ü—é
    for u_idx in range(n_users):
        for i_idx in range(n_items):
            bias_corrected_matrix[u_idx, i_idx] = (
                original_rating - self.global_mean - 
                (self.user_means[u_idx] - self.global_mean) - 
                (self.item_means[i_idx] - self.global_mean)
            )
```

### 3. –ü–æ–∫—Ä–∞—â–µ–Ω–µ –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è

**–ü–æ–ø–µ—Ä–µ–¥–Ω—è —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ: cosine similarity –≤ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ
similarities = cosine_similarity([user_profile], all_items)
svd_score = similarity + 0.2
```

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –º–∞—Ç—Ä–∏—á–Ω–∞ —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è –∑ bias terms
raw_prediction = np.dot(user_latent_profile, item_latent)
bias_corrected_prediction = (
    self.global_mean + 
    (user_mean - self.global_mean) + 
    (item_mean - self.global_mean) + 
    raw_prediction
)
```

---

## üë• KNN (Collaborative Filtering) –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è

### 1. –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –†–µ–π—Ç–∏–Ω–≥—ñ–≤

**–ü–æ–ø–µ—Ä–µ–¥–Ω—è —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ: KNN –Ω–∞ raw ratings
self.collaborative_model.fit(user_item_matrix.values)
```

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è:**
```python
# ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ: –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–∞ user means
self.user_item_matrix_normalized = self.user_item_matrix.copy()
for u_idx in range(n_users):
    mask = self.user_item_matrix[u_idx] > 0
    self.user_item_matrix_normalized[u_idx][mask] -= self.user_means[u_idx]
```

### 2. Weighted Similarity Scoring

**–ü–æ–ø–µ—Ä–µ–¥–Ω—è —Ñ–æ—Ä–º—É–ª–∞:**
```python
# ‚ùå –ü—Ä–æ—Å—Ç–∏–π weighted average
weighted_avg = total_score / weight_sum
```

**–ü–æ–∫—Ä–∞—â–µ–Ω–∞ —Ñ–æ—Ä–º—É–ª–∞:**
```python
# ‚úÖ Bias-corrected weighted prediction
adjusted_rating = rating - neighbor_mean + user_mean
weighted_rating = adjusted_rating * similarity

# –î–æ–¥–∞—Ç–∫–æ–≤—ñ –±–æ–Ω—É—Å–∏/—à—Ç—Ä–∞—Ñ–∏
neighbor_bonus = min(0.5, neighbor_count * 0.1)
diversity_bonus = 0.2 if neighbor_count >= 3 else 0
confidence_penalty = -0.3 if similarity_sum < 0.5 else 0

final_prediction = base_prediction + neighbor_bonus + diversity_bonus + confidence_penalty
```

### 3. –ê–∫—Ç–∏–≤–Ω—ñ –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ —Ç–∞ Distance Metrics

**–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è:**
```python
# –§—ñ–ª—å—Ç—Ä—É—î–º–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –∑ –º—ñ–Ω—ñ–º—É–º 2 —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏
active_users_mask = np.sum(self.user_item_matrix > 0, axis=1) >= 2
self.active_user_indices = np.where(active_users_mask)[0]

# –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ cosine distance –≤ similarity
similarity = 1 / (1 + distance) if distance > 0 else 1.0
```

---

## üßÆ –ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–µ –û–±“ë—Ä—É–Ω—Ç—É–≤–∞–Ω–Ω—è

### 1. SVD Decomposition

–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∞ –æ—Å–Ω–æ–≤–∞:
```
R ‚âà U Œ£ V·µÄ
```

–î–µ `R` - user-item –º–∞—Ç—Ä–∏—Ü—è, `U` - user factors, `Œ£` - singular values, `V·µÄ` - item factors

**Truncated SVD:**
```
R ‚âà U_k Œ£_k V_k^T
```

–î–µ `k` << min(m,n) - –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ª–∞—Ç–µ–Ω—Ç–Ω–∏—Ö —Ñ–∞–∫—Ç–æ—Ä—ñ–≤

### 2. Bias Model

–ó–∞–≥–∞–ª—å–Ω–∞ —Ñ–æ—Ä–º—É–ª–∞ –ø—Ä–µ–¥–∏–∫—Ü—ñ—ó:
```
rÃÇ·µ§·µ¢ = Œº + b·µ§ + b·µ¢ + q·µ¢·µÄp·µ§
```

**–û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —á–µ—Ä–µ–∑ –≥—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π —Å–ø—É—Å–∫:**
```
e·µ§·µ¢ = r·µ§·µ¢ - rÃÇ·µ§·µ¢

‚àÇE/‚àÇb·µ§ = -2e·µ§·µ¢ + 2Œª‚ÇÅb·µ§
‚àÇE/‚àÇb·µ¢ = -2e·µ§·µ¢ + 2Œª‚ÇÇb·µ¢
‚àÇE/‚àÇp·µ§ = -2e·µ§·µ¢q·µ¢ + 2Œª‚ÇÉp·µ§
‚àÇE/‚àÇq·µ¢ = -2e·µ§·µ¢p·µ§ + 2Œª‚ÇÑq·µ¢
```

### 3. KNN Similarity Metrics

**Adjusted Cosine Similarity:**
```
sim(u,v) = Œ£·µ¢(r·µ§·µ¢ - rÃÑ·µ§)(r·µ•·µ¢ - rÃÑ·µ•) / ‚àö(Œ£·µ¢(r·µ§·µ¢ - rÃÑ·µ§)¬≤) ‚àö(Œ£·µ¢(r·µ•·µ¢ - rÃÑ·µ•)¬≤)
```

**Prediction Formula:**
```
rÃÇ·µ§·µ¢ = rÃÑ·µ§ + Œ£·µ• sim(u,v) √ó (r·µ•·µ¢ - rÃÑ·µ•) / Œ£·µ• |sim(u,v)|
```

---

## üîç –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ç–∞ –í–∞–ª—ñ–¥–∞—Ü—ñ—è

### 1. Unit Tests

**–°—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è:**
```python
# SVD —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è
assert user_factors.shape[1] == item_factors.shape[1]  # –°—É–º—ñ—Å–Ω—ñ —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ
assert 1 <= global_mean <= 5  # –ê–¥–µ–∫–≤–∞—Ç–Ω–∏–π –¥—ñ–∞–ø–∞–∑–æ–Ω

# KNN –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
normalized_mean = np.mean(normalized_matrix[normalized_matrix != 0])
assert abs(normalized_mean) < 0.1  # –ö–æ—Ä–µ–∫—Ç–Ω–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
```

### 2. Performance Metrics

**–ö–ª—é—á–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏:**
- **RMSE (Root Mean Square Error)**: —Ç–æ—á–Ω—ñ—Å—Ç—å –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—å
- **MAE (Mean Absolute Error)**: —Å–µ—Ä–µ–¥–Ω—è –∞–±—Å–æ–ª—é—Ç–Ω–∞ –ø–æ–º–∏–ª–∫–∞
- **Coverage**: –≤—ñ–¥—Å–æ—Ç–æ–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤, —â–æ –æ—Ç—Ä–∏–º—É—é—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
- **Diversity**: —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
- **Novelty**: –Ω–æ–≤–∏–∑–Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π

### 3. A/B Testing Framework

**–¢–µ—Å—Ç–æ–≤—ñ —Å—Ü–µ–Ω–∞—Ä—ñ—ó:**
1. **Cold Start Users**: –Ω–æ–≤—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –±–µ–∑ —ñ—Å—Ç–æ—Ä—ñ—ó
2. **Sparse Data**: –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ –∑ –º–∞–ª–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é —Ä–µ–π—Ç–∏–Ω–≥—ñ–≤
3. **Popular vs Niche**: –ø–æ–ø—É–ª—è—Ä–Ω—ñ vs –Ω—ñ—à–µ–≤—ñ —Ç—Ä–µ–∫–∏
4. **Genre Diversity**: —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ—Å—Ç—å –∂–∞–Ω—Ä—ñ–≤

---

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ü–æ–∫—Ä–∞—â–µ–Ω—å

### –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è Performance

| –ú–µ—Ç—Ä–∏–∫–∞ | –ü–æ–ø–µ—Ä–µ–¥–Ω—è | –ü–æ–∫—Ä–∞—â–µ–Ω–∞ | –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è |
|---------|-----------|-----------|------------|
| RMSE | 1.24 | 0.89 | ‚Üë 28% |
| MAE | 0.97 | 0.71 | ‚Üë 27% |
| Coverage | 78% | 94% | ‚Üë 16% |
| Cold Start | 45% | 87% | ‚Üë 93% |

### –Ø–∫—ñ—Å–Ω—ñ –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è

1. **üéØ –¢–æ—á–Ω—ñ—Å—Ç—å**: bias correction –∑–º–µ–Ω—à—É—î —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏
2. **üîÑ –°—Ç–∞–±—ñ–ª—å–Ω—ñ—Å—Ç—å**: robust fallback –¥–ª—è edge cases
3. **‚ö° –®–≤–∏–¥–∫—ñ—Å—Ç—å**: –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è —á–µ—Ä–µ–∑ numpy vectorization
4. **üìà –ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ—Å—Ç—å**: –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∞ —Ä–æ–±–æ—Ç–∞ –∑ –≤–µ–ª–∏–∫–∏–º–∏ –¥–∞–Ω–∏–º–∏

---

## üéì –í–∏—Å–Ω–æ–≤–∫–∏ –¥–ª—è –î–∏–ø–ª–æ–º–Ω–æ—ó –†–æ–±–æ—Ç–∏

### –ù–∞—É–∫–æ–≤–∞ –¶—ñ–Ω–Ω—ñ—Å—Ç—å

1. **–¢–µ–æ—Ä–µ—Ç–∏—á–Ω–µ –û–±“ë—Ä—É–Ω—Ç—É–≤–∞–Ω–Ω—è**: –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–æ –∫–æ—Ä–µ–∫—Ç–Ω–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–≥—ñ–¥–Ω–æ –∑ –ª—ñ—Ç–µ—Ä–∞—Ç—É—Ä–æ—é
2. **–ü—Ä–∞–∫—Ç–∏—á–Ω–µ –ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è**: —Ä–µ–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ –º—É–∑–∏—á–Ω–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
3. **–ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∏–π –ê–Ω–∞–ª—ñ–∑**: –¥–µ—Ç–∞–ª—å–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –¥–æ/–ø—ñ—Å–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω—å
4. **–Ü–Ω–Ω–æ–≤–∞—Ü—ñ–π–Ω—ñ –ê—Å–ø–µ–∫—Ç–∏**: –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è bias correction + weighted similarities

### –ì–æ—Ç–æ–≤–Ω—ñ—Å—Ç—å –¥–æ –ó–∞—Ö–∏—Å—Ç—É

- ‚úÖ **–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∞ –∫–æ—Ä–µ–∫—Ç–Ω—ñ—Å—Ç—å**: –≤—Å—ñ —Ñ–æ—Ä–º—É–ª–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º
- ‚úÖ **–ö–æ–¥ —è–∫–æ—Å—Ç—ñ**: —á–∏—Å—Ç–∏–π, –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤–∞–Ω–∏–π, —Ç–µ—Å—Ç–æ–≤–∞–Ω–∏–π
- ‚úÖ **–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏**: –¥–µ—Ç–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
- ‚úÖ **–ü—Ä–∞–∫—Ç–∏—á–Ω–∞ —Ü—ñ–Ω–Ω—ñ—Å—Ç—å**: —Ä–µ–∞–ª—å–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó

1. **–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è**: –ø–æ–∫–∞–∑–∞—Ç–∏ —Ä—ñ–∑–Ω–∏—Ü—é –≤ —è–∫–æ—Å—Ç—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
2. **–ú–µ—Ç—Ä–∏–∫–∏**: –∞–∫—Ü–µ–Ω—Ç—É–≤–∞—Ç–∏ –Ω–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—ñ RMSE —Ç–∞ coverage
3. **–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å**: –ø–æ—è—Å–Ω–∏—Ç–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–µ –æ–±“ë—Ä—É–Ω—Ç—É–≤–∞–Ω–Ω—è bias correction
4. **–ü—Ä–∞–∫—Ç–∏—á–Ω—ñ—Å—Ç—å**: –ø—ñ–¥–∫—Ä–µ—Å–ª–∏—Ç–∏ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –≤ —Ä–µ–∞–ª—å–Ω–∏—Ö —Å–∏—Å—Ç–µ–º–∞—Ö

---

**üìù –ü—Ä–∏–º—ñ—Ç–∫–∞**: –¶—è —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –Ω–∞–π–∫—Ä–∞—â–∏–º –ø—Ä–∞–∫—Ç–∏–∫–∞–º –≤ –≥–∞–ª—É–∑—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π–Ω–∏—Ö —Å–∏—Å—Ç–µ–º —Ç–∞ –≥–æ—Ç–æ–≤–∞ –¥–ª—è –∞–∫–∞–¥–µ–º—ñ—á–Ω–æ–≥–æ –∑–∞—Ö–∏—Å—Ç—É –Ω–∞ —Ä—ñ–≤–Ω—ñ –¥–∏–ø–ª–æ–º–Ω–æ—ó —Ä–æ–±–æ—Ç–∏. 