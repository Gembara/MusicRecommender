import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
import joblib
import logging
from typing import List, Dict, Tuple
from data_loader import DataLoader

logger = logging.getLogger(__name__)

class MusicRecommenderML:
    def __init__(self):
        self.data_loader = DataLoader()
        self.content_model = None  # Content-based –º–æ–¥–µ–ª—å
        self.collaborative_model = None  # Collaborative filtering –º–æ–¥–µ–ª—å
        self.scaler = StandardScaler()
        self.feature_columns = [
            'Danceability', 'Energy', 'Valence', 'Tempo_norm',
            'Acousticness', 'Instrumentalness', 'Speechiness',
            'Loudness_norm', 'Popularity'
        ]
        self.is_trained = False
        
    def train_models(self) -> Dict[str, float]:
        """
        –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –æ–±–æ—Ö –º–æ–¥–µ–ª–µ–π:
        1. Content-Based: Random Forest –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ü—ñ—ó —Ä–µ–π—Ç–∏–Ω–≥—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∞—É–¥—ñ–æ —Ñ—ñ—á–µ–π
        2. Collaborative: KNN –¥–ª—è –∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è —Å—Ö–æ–∂–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
        """
        logger.info("üéØ –ü–æ—á–∞—Ç–æ–∫ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è ML –º–æ–¥–µ–ª–µ–π...")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ
        training_data, all_features = self.data_loader.prepare_training_data()
        
        if training_data.empty:
            logger.error("‚ùå –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è!")
            return {"error": "–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è"}
        
        logger.info(f"üìä –î–∞–Ω—ñ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è: {len(training_data)} –∑–∞–ø–∏—Å—ñ–≤")
        
        # 1. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è Content-Based –º–æ–¥–µ–ª—ñ
        content_metrics = self._train_content_based_model(training_data)
        
        # 2. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è Collaborative Filtering –º–æ–¥–µ–ª—ñ
        collaborative_metrics = self._train_collaborative_model(training_data)
        
        self.is_trained = True
        
        metrics = {
            **content_metrics,
            **collaborative_metrics,
            "total_training_samples": len(training_data),
            "unique_users": training_data['UserId'].nunique(),
            "unique_tracks": training_data['SpotifyTrackId'].nunique()
        }
        
        logger.info("‚úÖ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
        return metrics
    
    def _train_content_based_model(self, data: pd.DataFrame) -> Dict[str, float]:
        """–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è Content-Based –º–æ–¥–µ–ª—ñ"""
        logger.info("üéµ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è Content-Based –º–æ–¥–µ–ª—ñ...")
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ—ñ—á–µ–π
        X = data[self.feature_columns].fillna(0)
        y = data['Rating'].values
        
        # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Ñ—ñ—á–µ–π
        X_scaled = self.scaler.fit_transform(X)
        
        # –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π —Ç–∞ —Ç–µ—Å—Ç–æ–≤–∏–π –Ω–∞–±–æ—Ä–∏
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42
        )
        
        # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è Random Forest
        self.content_model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        
        self.content_model.fit(X_train, y_train)
        
        # –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ
        y_pred = self.content_model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        
        # –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å —Ñ—ñ—á–µ–π
        feature_importance = dict(zip(
            self.feature_columns,
            self.content_model.feature_importances_
        ))
        
        logger.info(f"üìà Content Model - MSE: {mse:.3f}, MAE: {mae:.3f}")
        logger.info(f"üîç –ù–∞–π–≤–∞–∂–ª–∏–≤—ñ—à—ñ —Ñ—ñ—á—ñ: {sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:3]}")
        
        return {
            "content_mse": mse,
            "content_mae": mae,
            "content_feature_importance": feature_importance
        }
    
    def _train_collaborative_model(self, data: pd.DataFrame) -> Dict[str, float]:
        """–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è Collaborative Filtering –º–æ–¥–µ–ª—ñ"""
        logger.info("üë• –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è Collaborative Filtering –º–æ–¥–µ–ª—ñ...")
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –º–∞—Ç—Ä–∏—Ü—é user-item
        user_item_matrix = data.pivot_table(
            index='UserId',
            columns='SpotifyTrackId',
            values='Rating',
            fill_value=0
        )
        
        # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è KNN –º–æ–¥–µ–ª—ñ
        self.collaborative_model = NearestNeighbors(
            n_neighbors=min(5, len(user_item_matrix) - 1),
            metric='cosine',
            algorithm='brute'
        )
        
        self.collaborative_model.fit(user_item_matrix.values)
        self.user_item_matrix = user_item_matrix
        
        # –ü—Ä–æ—Å—Ç–∏–π —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ç–æ—á–Ω–æ—Å—Ç—ñ
        sparsity = 1 - (data.shape[0] / (user_item_matrix.shape[0] * user_item_matrix.shape[1]))
        
        logger.info(f"üîç Collaborative Model - –†–æ–∑—Ä—ñ–¥–∂–µ–Ω—ñ—Å—Ç—å –º–∞—Ç—Ä–∏—Ü—ñ: {sparsity:.3f}")
        logger.info(f"üë§ –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤: {user_item_matrix.shape[0]}, üéµ –¢—Ä–µ–∫—ñ–≤: {user_item_matrix.shape[1]}")
        
        return {
            "collaborative_sparsity": sparsity,
            "collaborative_users": user_item_matrix.shape[0],
            "collaborative_items": user_item_matrix.shape[1]
        }
    
    def get_content_recommendations(self, user_id: int, limit: int = 20) -> List[Dict]:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–Ω—Ç–µ–Ω—Ç—É (–∞—É–¥—ñ–æ —Ñ—ñ—á—ñ)"""
        if not self.is_trained or self.content_model is None:
            logger.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∞!")
            return []
        
        logger.info(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è content-based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ {user_id}")
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –ø—Ä–æ—Ñ—ñ–ª—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        user_profile = self.data_loader.get_user_profile(user_id)
        if not user_profile:
            logger.warning(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ—Ñ—ñ–ª—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ {user_id}")
            return []
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ —Ç—Ä–µ–∫–∏
        all_features = self.data_loader.load_song_features()
        if all_features.empty:
            return []
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ç—Ä–µ–∫–∏, —è–∫—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –≤–∂–µ —Å–ª—É—Ö–∞–≤ (–∑ —É—Å—ñ—Ö –¥–∂–µ—Ä–µ–ª)
        user_interactions = self.data_loader.load_user_interactions()
        user_tracks = user_interactions[user_interactions['UserId'] == user_id]['SpotifyTrackId'].unique()
        listened_tracks = set(user_tracks)
        
        logger.info(f"–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á {user_id} –º–∞—î {len(listened_tracks)} —Ç—Ä–µ–∫—ñ–≤ –≤ —ñ—Å—Ç–æ—Ä—ñ—ó: {list(listened_tracks)[:5]}...")
        
        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –Ω–æ–≤—ñ —Ç—Ä–µ–∫–∏ (—è–∫—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –ù–ï —Å–ª—É—Ö–∞–≤)
        new_tracks = all_features[~all_features['SpotifyTrackId'].isin(listened_tracks)]
        
        logger.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(new_tracks)} –Ω–æ–≤–∏—Ö —Ç—Ä–µ–∫—ñ–≤ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó")
        
        if new_tracks.empty:
            logger.warning("‚ùå –ù–µ–º–∞—î –Ω–æ–≤–∏—Ö —Ç—Ä–µ–∫—ñ–≤ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó")
            return []
        
        # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ —Ñ—ñ—á—ñ –Ω–æ–≤–∏—Ö —Ç—Ä–µ–∫—ñ–≤
        new_tracks = new_tracks.copy()
        new_tracks['Tempo_norm'] = (new_tracks['Tempo'] - new_tracks['Tempo'].min()) / (new_tracks['Tempo'].max() - new_tracks['Tempo'].min())
        new_tracks['Loudness_norm'] = (new_tracks['Loudness'] - new_tracks['Loudness'].min()) / (new_tracks['Loudness'].max() - new_tracks['Loudness'].min())
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ—ñ—á–µ–π –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ü—ñ—ó
        X_new = new_tracks[self.feature_columns].fillna(0)
        X_new_scaled = self.scaler.transform(X_new)
        
        # –ü—Ä–µ–¥–∏–∫—Ü—ñ—è —Ä–µ–π—Ç–∏–Ω–≥—ñ–≤
        predicted_ratings = self.content_model.predict(X_new_scaled)
        
        # –î–æ–¥–∞—î–º–æ –ø—Ä–µ–¥–∏–∫–æ–≤–∞–Ω—ñ —Ä–µ–π—Ç–∏–Ω–≥–∏
        new_tracks = new_tracks.copy()
        new_tracks['predicted_rating'] = predicted_ratings
        
        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –ø—Ä–µ–¥–∏–∫–æ–≤–∞–Ω–∏–º —Ä–µ–π—Ç–∏–Ω–≥–æ–º
        recommendations = new_tracks.nlargest(limit, 'predicted_rating')
        
        # –§–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
        result = []
        for _, track in recommendations.iterrows():
            result.append({
                'track_id': track['SpotifyTrackId'],
                'title': track.get('Title', 'Unknown Track'),
                'artist': track.get('Artist', 'Unknown'),
                'predicted_rating': float(track['predicted_rating']),
                'reason': 'Content-Based: —Å—Ö–æ–∂—ñ –∞—É–¥—ñ–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏',
                'features': {
                    'danceability': float(track['Danceability']),
                    'energy': float(track['Energy']),
                    'valence': float(track['Valence']),
                    'genre': track.get('Genre', 'Unknown')
                }
            })
        
        logger.info(f"‚úÖ –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ {len(result)} content-based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π")
        return result
    
    def get_collaborative_recommendations(self, user_id: int, limit: int = 20) -> List[Dict]:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Å—Ö–æ–∂–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤"""
        if not self.is_trained or self.collaborative_model is None:
            logger.warning("‚ö†Ô∏è Collaborative –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∞!")
            return []
        
        logger.info(f"üë• –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è collaborative —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ {user_id}")
        
        if user_id not in self.user_item_matrix.index:
            logger.warning(f"‚ùå –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á {user_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∏–π —É –º–∞—Ç—Ä–∏—Ü—ñ")
            return []
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —Å—Ö–æ–∂–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
        user_idx = self.user_item_matrix.index.get_loc(user_id)
        user_vector = self.user_item_matrix.iloc[user_idx].values.reshape(1, -1)
        
        distances, indices = self.collaborative_model.kneighbors(user_vector)
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –≤—ñ–¥ —Å—Ö–æ–∂–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
        similar_users = [self.user_item_matrix.index[i] for i in indices[0][1:]]  # –í–∏–∫–ª—é—á–∞—î–º–æ —Å–∞–º–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        
        # –ê–≥—Ä–µ–≥—É—î–º–æ —Ä–µ–π—Ç–∏–Ω–≥–∏ –≤—ñ–¥ —Å—Ö–æ–∂–∏—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
        recommendations_scores = {}
        user_tracks = set(self.user_item_matrix.columns[self.user_item_matrix.iloc[user_idx] > 0])
        
        for similar_user_id in similar_users:
            similar_user_idx = self.user_item_matrix.index.get_loc(similar_user_id)
            similar_user_ratings = self.user_item_matrix.iloc[similar_user_idx]
            
            # –†–µ–∫–æ–º–µ–Ω–¥—É—î–º–æ —Ç—Ä–µ–∫–∏, —è–∫—ñ –ø–æ–¥–æ–±–∞–ª–∏—Å—å —Å—Ö–æ–∂–∏–º –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞–º, –∞–ª–µ –Ω–µ —Å–ª—É—Ö–∞–≤ –ø–æ—Ç–æ—á–Ω–∏–π
            for track_id, rating in similar_user_ratings[similar_user_ratings > 3].items():
                if track_id not in user_tracks:
                    if track_id not in recommendations_scores:
                        recommendations_scores[track_id] = []
                    recommendations_scores[track_id].append(rating)
        
        # –û–±—á–∏—Å–ª—é—î–º–æ —Å–µ—Ä–µ–¥–Ω—ñ —Ä–µ–π—Ç–∏–Ω–≥–∏
        avg_recommendations = {
            track_id: np.mean(ratings) 
            for track_id, ratings in recommendations_scores.items()
        }
        
        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —Ä–µ–π—Ç–∏–Ω–≥–æ–º
        sorted_recommendations = sorted(
            avg_recommendations.items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:limit]
        
        # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ç—Ä–µ–∫–∏
        all_features = self.data_loader.load_song_features()
        result = []
        
        for track_id, predicted_rating in sorted_recommendations:
            track_info = all_features[all_features['SpotifyTrackId'] == track_id]
            if not track_info.empty:
                track = track_info.iloc[0]
                result.append({
                    'track_id': track_id,
                    'title': track.get('Title', 'Unknown Track'),
                    'artist': track.get('Artist', 'Unknown'),
                    'predicted_rating': float(predicted_rating),
                    'reason': f'Collaborative: —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ —Å—Ö–æ–∂–∏–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞–º–∏ {similar_users[:2]}',
                    'features': {
                        'danceability': float(track['Danceability']),
                        'energy': float(track['Energy']),
                        'valence': float(track['Valence']),
                        'genre': track.get('Genre', 'Unknown')
                    }
                })
        
        logger.info(f"‚úÖ –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ {len(result)} collaborative —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π")
        return result
    
    def get_hybrid_recommendations(self, user_id: int, limit: int = 20) -> List[Dict]:
        """–ì—ñ–±—Ä–∏–¥–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó (–∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è content-based + collaborative)"""
        logger.info(f"üîÄ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≥—ñ–±—Ä–∏–¥–Ω–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ {user_id}")
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –∑ –æ–±–æ—Ö –º–æ–¥–µ–ª–µ–π
        content_recs = self.get_content_recommendations(user_id, limit * 2)
        collaborative_recs = self.get_collaborative_recommendations(user_id, limit * 2)
        
        # –ö–æ–º–±—ñ–Ω—É—î–º–æ –∑ –≤–∞–≥–∞–º–∏: 60% content + 40% collaborative
        combined_scores = {}
        
        for rec in content_recs:
            track_id = rec['track_id']
            combined_scores[track_id] = {
                'score': rec['predicted_rating'] * 0.6,
                'info': rec,
                'methods': ['content']
            }
        
        for rec in collaborative_recs:
            track_id = rec['track_id']
            if track_id in combined_scores:
                combined_scores[track_id]['score'] += rec['predicted_rating'] * 0.4
                combined_scores[track_id]['methods'].append('collaborative')
            else:
                combined_scores[track_id] = {
                    'score': rec['predicted_rating'] * 0.4,
                    'info': rec,
                    'methods': ['collaborative']
                }
        
        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–º —Å–∫–æ—Ä–æ–º
        sorted_combined = sorted(
            combined_scores.items(),
            key=lambda x: x[1]['score'],
            reverse=True
        )[:limit]
        
        # –§–æ—Ä–º–∞—Ç—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = []
        for track_id, data in sorted_combined:
            info = data['info'].copy()
            info['predicted_rating'] = float(data['score'])
            info['reason'] = f"Hybrid: {', '.join(data['methods'])}"
            result.append(info)
        
        logger.info(f"‚úÖ –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ {len(result)} –≥—ñ–±—Ä–∏–¥–Ω–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π")
        return result
    
    def save_models(self, path: str = "models/"):
        """–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        import os
        os.makedirs(path, exist_ok=True)
        
        if self.content_model:
            joblib.dump(self.content_model, f"{path}/content_model.pkl")
            joblib.dump(self.scaler, f"{path}/scaler.pkl")
        
        if self.collaborative_model:
            joblib.dump(self.collaborative_model, f"{path}/collaborative_model.pkl")
            joblib.dump(self.user_item_matrix, f"{path}/user_item_matrix.pkl")
        
        logger.info(f"üíæ –ú–æ–¥–µ–ª—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ {path}")
    
    def load_models(self, path: str = "models/"):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        import os
        try:
            if os.path.exists(f"{path}/content_model.pkl"):
                self.content_model = joblib.load(f"{path}/content_model.pkl")
                self.scaler = joblib.load(f"{path}/scaler.pkl")
            
            if os.path.exists(f"{path}/collaborative_model.pkl"):
                self.collaborative_model = joblib.load(f"{path}/collaborative_model.pkl")
                self.user_item_matrix = joblib.load(f"{path}/user_item_matrix.pkl")
            
            self.is_trained = True
            logger.info(f"üì• –ú–æ–¥–µ–ª—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑ {path}")
            return True
        except Exception as e:
            logger.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π: {e}")
            return False 