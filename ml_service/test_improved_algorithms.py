#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –ø–æ–∫—Ä–∞—â–µ–Ω–∏—Ö SVD —Ç–∞ KNN –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤
"""

import sys
import os
sys.path.append('.')

from ml_models import MusicRecommenderML
from data_loader import DataLoader
import pandas as pd
import numpy as np
import time

def test_improved_algorithms():
    """–î–µ—Ç–∞–ª—å–Ω–∏–π —Ç–µ—Å—Ç –ø–æ–∫—Ä–∞—â–µ–Ω–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤"""
    
    print("üéØ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–∏—Ö SVD —Ç–∞ KNN –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤")
    print("=" * 60)
    
    # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
    ml_model = MusicRecommenderML()
    data_loader = DataLoader()
    
    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö
    print("\n1Ô∏è‚É£ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö...")
    try:
        training_data, all_features = data_loader.prepare_training_data()
        if training_data.empty:
            print("‚ùå –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è!")
            return
        
        print(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(training_data)} –∑–∞–ø–∏—Å—ñ–≤")
        print(f"üë§ –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤: {training_data['UserId'].nunique()}")
        print(f"üéµ –¢—Ä–µ–∫—ñ–≤: {training_data['SpotifyTrackId'].nunique()}")
        print(f"üìä –°–µ—Ä–µ–¥–Ω—ñ–π —Ä–µ–π—Ç–∏–Ω–≥: {training_data['Rating'].mean():.2f}")
        
        # –ü–æ–∫–∞–∑—É—î–º–æ —Ä–æ–∑–ø–æ–¥—ñ–ª —Ä–µ–π—Ç–∏–Ω–≥—ñ–≤
        rating_dist = training_data['Rating'].value_counts().sort_index()
        print(f"üìà –†–æ–∑–ø–æ–¥—ñ–ª —Ä–µ–π—Ç–∏–Ω–≥—ñ–≤: {dict(rating_dist)}")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")
        return
    
    # 2. –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π
    print("\n2Ô∏è‚É£ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π...")
    start_time = time.time()
    
    try:
        metrics = ml_model.train_models()
        training_time = time.time() - start_time
        
        if "error" in metrics:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è: {metrics['error']}")
            return
        
        print(f"‚úÖ –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {training_time:.2f} —Å–µ–∫—É–Ω–¥")
        
        # –ü–æ–∫–∞–∑—É—î–º–æ –º–µ—Ç—Ä–∏–∫–∏
        print("\nüìä –ú–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è:")
        for key, value in metrics.items():
            if isinstance(value, float):
                print(f"   {key}: {value:.4f}")
            else:
                print(f"   {key}: {value}")
                
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è: {e}")
        return
    
    # 3. –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è KNN –∞–ª–≥–æ—Ä–∏—Ç–º—É
    print("\n3Ô∏è‚É£ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–æ–≥–æ KNN –∞–ª–≥–æ—Ä–∏—Ç–º—É...")
    test_user_ids = training_data['UserId'].unique()[:3]  # –ü–µ—Ä—à—ñ 3 –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ
    
    for user_id in test_user_ids:
        print(f"\nüë§ –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á {user_id}:")
        
        try:
            start_time = time.time()
            knn_recs = ml_model.get_collaborative_recommendations(user_id, limit=5)
            knn_time = time.time() - start_time
            
            if knn_recs:
                print(f"‚úÖ KNN: {len(knn_recs)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –∑–∞ {knn_time:.3f}s")
                
                for i, rec in enumerate(knn_recs[:2], 1):
                    print(f"   {i}. {rec['artist']} - {rec['title']}")
                    print(f"      üìä –†–µ–π—Ç–∏–Ω–≥: {rec['predicted_rating']:.2f}")
                    print(f"      üë• –°—É—Å—ñ–¥—ñ–≤: {rec.get('neighbor_count', 0)}")
                    print(f"      üéØ Confidence: {rec.get('confidence', 0):.3f}")
                    print(f"      ‚öñÔ∏è Bias correction: {rec.get('bias_corrected', False)}")
                    
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º—É
                avg_confidence = np.mean([r['confidence'] for r in knn_recs])
                print(f"   üìà –°–µ—Ä–µ–¥–Ω—è –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: {avg_confidence:.3f}")
                
            else:
                print("‚ö†Ô∏è KNN: –ù–µ–º–∞—î —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π")
                
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ KNN –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ {user_id}: {e}")
    
    # 4. –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è SVD –∞–ª–≥–æ—Ä–∏—Ç–º—É
    print("\n4Ô∏è‚É£ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–æ–≥–æ SVD –∞–ª–≥–æ—Ä–∏—Ç–º—É...")
    
    for user_id in test_user_ids:
        print(f"\nüë§ –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á {user_id}:")
        
        try:
            start_time = time.time()
            svd_recs = ml_model.get_svd_recommendations(user_id, limit=5)
            svd_time = time.time() - start_time
            
            if svd_recs:
                print(f"‚úÖ SVD: {len(svd_recs)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –∑–∞ {svd_time:.3f}s")
                
                for i, rec in enumerate(svd_recs[:2], 1):
                    print(f"   {i}. {rec['artist']} - {rec['title']}")
                    print(f"      üìä –†–µ–π—Ç–∏–Ω–≥: {rec['predicted_rating']:.2f}")
                    print(f"      üîß Raw SVD: {rec.get('raw_svd_score', 0):.3f}")
                    print(f"      ‚öñÔ∏è User bias: {rec.get('user_bias', 0):.3f}")
                    print(f"      üéØ Item bias: {rec.get('item_bias', 0):.3f}")
                    print(f"      üîÄ Matrix factorization: {rec.get('matrix_factorization', False)}")
                    
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —è–∫—ñ—Å—Ç—å SVD
                avg_raw_score = np.mean([r.get('raw_svd_score', 0) for r in svd_recs])
                print(f"   üìà –°–µ—Ä–µ–¥–Ω—ñ–π raw SVD score: {avg_raw_score:.3f}")
                
            else:
                print("‚ö†Ô∏è SVD: –ù–µ–º–∞—î —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π")
                
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ SVD –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ {user_id}: {e}")
    
    # 5. –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤
    print("\n5Ô∏è‚É£ –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤...")
    
    test_user = test_user_ids[0]  # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    
    try:
        print(f"\nüîç –î–µ—Ç–∞–ª—å–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ {test_user}:")
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –≤—ñ–¥ —É—Å—ñ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤
        content_recs = ml_model.get_content_recommendations(test_user, 3)
        knn_recs = ml_model.get_collaborative_recommendations(test_user, 3)
        svd_recs = ml_model.get_svd_recommendations(test_user, 3)
        hybrid_recs = ml_model.get_hybrid_recommendations(test_user, 3)
        
        algorithms = [
            ("Content-Based", content_recs),
            ("Improved KNN", knn_recs),
            ("Improved SVD", svd_recs),
            ("Hybrid", hybrid_recs)
        ]
        
        for alg_name, recs in algorithms:
            if recs:
                avg_rating = np.mean([r['predicted_rating'] for r in recs])
                unique_tracks = len(set(r['track_id'] for r in recs))
                print(f"   {alg_name}: {len(recs)} —Ä–µ–∫., avg={avg_rating:.2f}, unique={unique_tracks}")
            else:
                print(f"   {alg_name}: –ù–µ–º–∞—î —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ—Å—Ç—å
        all_track_ids = set()
        for _, recs in algorithms:
            all_track_ids.update(r['track_id'] for r in recs)
        
        print(f"\nüé® –ó–∞–≥–∞–ª—å–Ω–∞ —Ä—ñ–∑–Ω–æ–º–∞–Ω—ñ—Ç–Ω—ñ—Å—Ç—å: {len(all_track_ids)} —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Ç—Ä–µ–∫—ñ–≤")
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è: {e}")
    
    # 6. –¢–µ—Å—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–æ—ó –∫–æ—Ä–µ–∫—Ç–Ω–æ—Å—Ç—ñ
    print("\n6Ô∏è‚É£ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–æ—ó –∫–æ—Ä–µ–∫—Ç–Ω–æ—Å—Ç—ñ...")
    
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ SVD —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—é
        if hasattr(ml_model, 'svd_user_factors') and ml_model.svd_user_factors is not None:
            user_factors_shape = ml_model.svd_user_factors.shape
            item_factors_shape = ml_model.svd_item_factors.shape
            
            print(f"‚úÖ SVD —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è:")
            print(f"   üë§ User factors: {user_factors_shape}")
            print(f"   üéµ Item factors: {item_factors_shape}")
            print(f"   üîß –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤: {user_factors_shape[1]}")
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è —Ä–æ–±–∏—Ç—å —Å–µ–Ω—Å
            if user_factors_shape[1] == item_factors_shape[1]:
                print("   ‚úÖ –†–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ —Ñ–∞–∫—Ç–æ—Ä—ñ–≤ —Å—É–º—ñ—Å–Ω—ñ")
            else:
                print("   ‚ùå –†–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ —Ñ–∞–∫—Ç–æ—Ä—ñ–≤ –Ω–µ—Å—É–º—ñ—Å–Ω—ñ!")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ bias terms
        if hasattr(ml_model, 'user_means') and ml_model.user_means is not None:
            user_mean_range = (ml_model.user_means.min(), ml_model.user_means.max())
            global_mean = ml_model.global_mean
            
            print(f"‚úÖ Bias correction:")
            print(f"   üåç –ì–ª–æ–±–∞–ª—å–Ω–∏–π —Å–µ—Ä–µ–¥–Ω—ñ–π: {global_mean:.3f}")
            print(f"   üë§ User bias range: [{user_mean_range[0]:.3f}, {user_mean_range[1]:.3f}]")
            
            if 1 <= global_mean <= 5:
                print("   ‚úÖ –ì–ª–æ–±–∞–ª—å–Ω–∏–π —Å–µ—Ä–µ–¥–Ω—ñ–π –≤ –º–µ–∂–∞—Ö –Ω–æ—Ä–º–∏")
            else:
                print("   ‚ö†Ô∏è –ì–ª–æ–±–∞–ª—å–Ω–∏–π —Å–µ—Ä–µ–¥–Ω—ñ–π –ø–æ–∑–∞ –º–µ–∂–∞–º–∏ 1-5")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ KNN –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—é
        if hasattr(ml_model, 'user_item_matrix_normalized') and ml_model.user_item_matrix_normalized is not None:
            normalized_mean = np.mean(ml_model.user_item_matrix_normalized[ml_model.user_item_matrix_normalized != 0])
            print(f"‚úÖ KNN –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è:")
            print(f"   üìä –°–µ—Ä–µ–¥–Ω—î –Ω–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–æ—ó –º–∞—Ç—Ä–∏—Ü—ñ: {normalized_mean:.6f}")
            
            if abs(normalized_mean) < 0.1:  # –ú–∞—î –±—É—Ç–∏ –±–ª–∏–∑—å–∫–æ –¥–æ 0
                print("   ‚úÖ –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–æ—Ä–µ–∫—Ç–Ω–∞")
            else:
                print("   ‚ö†Ô∏è –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –º–æ–∂–µ –±—É—Ç–∏ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–æ—é")
                
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∫–æ—Ä–µ–∫—Ç–Ω–æ—Å—Ç—ñ: {e}")
    
    print("\n" + "=" * 60)
    print("üéâ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("\nüîß –û—Å–Ω–æ–≤–Ω—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è:")
    print("   üìê SVD: –ø—Ä–∞–≤–∏–ª—å–Ω–∞ –º–∞—Ç—Ä–∏—á–Ω–∞ —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è –∑ bias correction")
    print("   üë• KNN: –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–π—Ç–∏–Ω–≥—ñ–≤ —Ç–∞ weighted similarities")
    print("   üéØ –û–±–∏–¥–≤–∞: –∫—Ä–∞—â—ñ fallback –º–µ—Ö–∞–Ω—ñ–∑–º–∏ —Ç–∞ –æ–±—Ä–æ–±–∫–∞ edge cases")
    print("   üìä –ü–æ–∫—Ä–∞—â–µ–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ —Ç–∞ —è–∫–æ—Å—Ç—ñ")

if __name__ == "__main__":
    test_improved_algorithms() 